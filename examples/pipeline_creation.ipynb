{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create a Pipeline\n",
    "We provide three ways of creating a pipeline.\n",
    "* Functional API\n",
    "* Imperative API\n",
    "* Constructor API\n",
    "\n",
    "In the following, we briefly describe all three APIs, before explaining the control flow under the hood."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# From pyWATTS the pipeline is imported\n",
    "from pywatts.callbacks import LinePlotCallback\n",
    "\n",
    "from pywatts_pipeline.core.steps.step import Step\n",
    "from pywatts_pipeline.core.util.computation_mode import ComputationMode\n",
    "from pywatts_pipeline.core.pipeline import Pipeline\n",
    "# All modules required for the pipeline are imported\n",
    "from pywatts.modules import CalendarExtraction, CalendarFeature, ClockShift, LinearInterpolater, SKLearnWrapper, Sampler\n",
    "from pywatts.modules.preprocessing.select import Select\n",
    "from pywatts.summaries import RMSE\n",
    "from load_data import load_elec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functional API\n",
    "\n",
    "The functional API provides an easy way to create pipelines. However, it requires that the call dunder is implemented in the used transformers/modules, which is the case for pyWATTS transformers.\n",
    "The API is inspired by the functional API of Keras. In general the notation is as follows:\n",
    "\n",
    "```Transformer()(x=predeccessor, y=predecessor, ...)```\n",
    "\n",
    "In the following, we show how a simple Pipeline can be created with the Functional API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\PycharmProjects\\pywatts-pipeline\\pywatts_pipeline\\core\\transformer\\base.py:209: UserWarning: The step with name scaled_target is renamed to scaled_target_1 due to naming conflicts.\n",
      "  warnings.warn(f\"The step with name {self.name} is renamed to {name} due to naming conflicts.\")\n"
     ]
    }
   ],
   "source": [
    "functional_api_pipeline = Pipeline(path=\"../results\")\n",
    "\n",
    "# Extract dummy calendar features, using holidays from Germany\n",
    "# NOTE: CalendarExtraction can't return multiple features.\n",
    "\n",
    "functional_preprocessing_pipeline = Pipeline()\n",
    "calendar = CalendarExtraction(continent=\"Europe\",\n",
    "                              country=\"Germany\",name=\"calendar\",\n",
    "                              features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                        CalendarFeature.weekend]\n",
    "                              )(x=functional_preprocessing_pipeline[\"load_power_statistics\"])\n",
    "imputer_power_statistics = LinearInterpolater(method=\"nearest\", dim=\"time\",\n",
    "                                              name=\"imputer_power\"\n",
    "                                              )(x=functional_preprocessing_pipeline[\"load_power_statistics\"])\n",
    "\n",
    "\n",
    "added_prepro_pipe = functional_preprocessing_pipeline(load_power_statistics=functional_api_pipeline[\"load_power_statistics\"])\n",
    "# Create lagged time series to later be used as regressors\n",
    "\n",
    "# Scale the data using a standard SKLearn scaler\n",
    "power_scaler = SKLearnWrapper(module=StandardScaler(), name=\"scaled_input\")\n",
    "scale_power_statistics = power_scaler(x=added_prepro_pipe[\"imputer_power\"])\n",
    "scaler_target = SKLearnWrapper(module=StandardScaler(), name=\"scaled_target\")\n",
    "scaled_target = scaler_target(x=added_prepro_pipe[\"imputer_power\"])\n",
    "lag_features = Select(start=-2, stop=0, step=1)(x=scale_power_statistics)\n",
    "target_multiple_output = Select(start=0, stop=24, step=1, name=\"sampled_data\")(x=scaled_target)\n",
    "\n",
    "# Select features based on F-statistic\n",
    "selected_features = SKLearnWrapper(\n",
    "    module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"\n",
    ")(\n",
    "    lag_features=lag_features,\n",
    "    calendar=added_prepro_pipe[\"calendar\"],\n",
    "    target=scale_power_statistics,\n",
    ")\n",
    "\n",
    "# Create a linear regression that uses the lagged values to predict the current value\n",
    "# NOTE: SKLearnWrapper has to collect all **kwargs itself and fit it against target.\n",
    "#       It is also possible to implement a join/collect class\n",
    "regressor_power_statistics = SKLearnWrapper(\n",
    "    module=LinearRegression(fit_intercept=True)\n",
    ")(\n",
    "    features=selected_features,\n",
    "    target=target_multiple_output,\n",
    "    callbacks=[LinePlotCallback(\"linear_regression\")],\n",
    ")\n",
    "\n",
    "# Rescale the predictions to be on the original time scale\n",
    "inverse_power_scale = scaler_target(\n",
    "    x=regressor_power_statistics, computation_mode=ComputationMode.Transform,\n",
    "    method=\"inverse_transform\", callbacks=[LinePlotCallback(\"rescale\")]\n",
    ")\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) between the linear regression and the true values\n",
    "# save it as csv file\n",
    "rmse = RMSE()(y_hat=inverse_power_scale, y=target_multiple_output)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imperative API\n",
    "\n",
    "The imperative API is an alternative API for pyWATTS Pipelines. It can be used if the transformers do not implement a call dunder.\n",
    "The general notation is as follows\n",
    "\n",
    "```TODO```\n",
    "\n",
    "In the following, we implement the same pipeline as above with a functional API."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<pywatts_pipeline.core.steps.step_information.StepInformation at 0x1f5e4d7abe0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperative_preprocessing_pipeline = Pipeline()\n",
    "\n",
    "\n",
    "imperative_preprocessing_pipeline.add(\n",
    "    CalendarExtraction(continent=\"Europe\", country=\"Germany\",\n",
    "                       features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                 CalendarFeature.weekend]),\n",
    "    \"calendar\",\n",
    "    {\"x\": \"load_power_statistics\"}\n",
    ")\n",
    "\n",
    "imperative_preprocessing_pipeline.add(\n",
    "    LinearInterpolater(method=\"nearest\", dim=\"time\", name=\"imputer_power\"),\n",
    "    \"imputer\",\n",
    "    {\"x\": \"load_power_statistics\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline = Pipeline()\n",
    "\n",
    "power_scaler = SKLearnWrapper(module=StandardScaler(), name=\"scaler_power\")\n",
    "\n",
    "imperative_api_pipeline.add(imperative_preprocessing_pipeline,\n",
    "                            \"preprocessing\",\n",
    "                            {\"load_power_statistics\": \"load_power_statistics\"})\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    power_scaler,\n",
    "    \"scaler\",\n",
    "    {\"x\": \"preprocessing__imputer\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    Select(start=-2, stop=0, step=1),\n",
    "    \"lag_features\",\n",
    "    {\"x\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    Select(start=0, stop=24, step=1),\n",
    "    \"target\",\n",
    "    {\"x\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    SKLearnWrapper(module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"),\n",
    "    \"selected_features\",\n",
    "    {\"lag_features\": \"lag_features\",\n",
    "     \"calendar\": \"preprocessing__calendar\",\n",
    "     \"target\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    SKLearnWrapper(module=LinearRegression(fit_intercept=True)),\n",
    "    \"regression\",\n",
    "    {\"selected_features\": \"selected_features\",\n",
    "     \"target\": \"target\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    power_scaler,\n",
    "    \"inverse_scaler\",\n",
    "    {\"x\": \"regression\"},\n",
    "    method=\"inverse_transform\",\n",
    "    callbacks=[LinePlotCallback(\"rescale\")],\n",
    "    computation_mode=ComputationMode.Transform\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    RMSE(),\n",
    "    \"rmse\",\n",
    "    {\"y_hat\": \"inverse_scaler\",\n",
    "     \"y\": \"target\"},\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "constructor_api_preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (CalendarExtraction(continent=\"Europe\", country=\"Germany\",\n",
    "                            features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                      CalendarFeature.weekend]),\n",
    "         \"calendar\",\n",
    "         {\"x\": \"load_power_statistics\"}, {}),\n",
    "        (LinearInterpolater(method=\"nearest\", dim=\"time\", name=\"imputer_power\"),\n",
    "         \"imputer\",\n",
    "         {\"x\": \"load_power_statistics\"}, {}),\n",
    "    ])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (constructor_api_preprocessing_pipeline,\n",
    "         \"preprocessing\",\n",
    "         {\"load_power_statistics\": \"load_power_statistics\"}, {}),\n",
    "        (power_scaler,\n",
    "         \"scaler\",\n",
    "         {\"x\": \"preprocessing__imputer\"}, {}),\n",
    "        (Select(start=-2, stop=0, step=1),\n",
    "         \"lag_features\",\n",
    "         {\"x\": \"scaler\"}, {}),\n",
    "        (Select(start=0, stop=24, step=1),\n",
    "         \"target\",\n",
    "         {\"x\": \"scaler\"}, {}),\n",
    "        (SKLearnWrapper(module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"),\n",
    "         \"selected_features\",\n",
    "         {\"lag_features\": \"lag_features\",\n",
    "          \"calendar\": \"preprocessing__calendar\",\n",
    "          \"target\": \"scaler\"}, {}),\n",
    "        (SKLearnWrapper(module=LinearRegression(fit_intercept=True)),\n",
    "         \"regression\",\n",
    "         {\"selected_features\": \"selected_features\",\n",
    "          \"target\": \"target\"}, {}),\n",
    "        (power_scaler,\n",
    "         \"inverse_scaler\",\n",
    "         {\"x\": \"regression\"},\n",
    "         {\"method\": \"inverse_transform\",\n",
    "          \"callbacks\": [LinePlotCallback(\"rescale\")],\n",
    "          \"computation_mode\": ComputationMode.Transform}),\n",
    "        (RMSE(),\n",
    "         \"rmse\",\n",
    "         {\"y_hat\": \"inverse_scaler\",\n",
    "          \"y\": \"target\"}, {})\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = load_elec_data()\n",
    "train = data.iloc[:6000, :]\n",
    "test = data.iloc[6000:, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# Summary: \\n## Summary\\n### RMSE\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### Pipeline Training Time\\n\\n*  : 0.0\\n### CalendarExtraction Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaler_power Training Time\\n\\n*  : 0.00030517578125\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.003983736038208008\\n### LinearRegression Training Time\\n\\n*  : 0.009963750839233398\\n## TransformTime\\n### Pipeline Transform Time\\n\\n*  : 0.018999338150024414\\n### CalendarExtraction Transform Time\\n\\n*  : 0.013932943344116211\\n### imputer_power Transform Time\\n\\n*  : 0.002999544143676758\\n### scaler_power Transform Time\\n\\n*  : 0.0010001659393310547\\n### SampleModule Transform Time\\n\\n*  : 0.008000612258911133\\n### SampleModule Transform Time\\n\\n*  : 0.06800007820129395\\n### kbest Transform Time\\n\\n*  : 0.0010004043579101562\\n### LinearRegression Transform Time\\n\\n*  : 0.0020003318786621094\\n### scaler_power Transform Time\\n\\n*  : 0.0010001659393310547\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train(data=train)\n",
    "pipeline.test(data=test)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# Summary: \\n## Summary\\n### RMSE\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### Pipeline Training Time\\n\\n*  : 0.0\\n### calendar Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaled_input Training Time\\n\\n*  : 0.0005431175231933594\\n### scaled_target Training Time\\n\\n*  : 0.0010008811950683594\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### sampled_data Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.003948688507080078\\n### LinearRegression Training Time\\n\\n*  : 0.008099079132080078\\n## TransformTime\\n### Pipeline Transform Time\\n\\n*  : 0.023000240325927734\\n### calendar Transform Time\\n\\n*  : 0.01699972152709961\\n### imputer_power Transform Time\\n\\n*  : 0.0039997100830078125\\n### scaled_input Transform Time\\n\\n*  : 0.0019998550415039062\\n### scaled_target Transform Time\\n\\n*  : 0.0009055137634277344\\n### SampleModule Transform Time\\n\\n*  : 0.009000778198242188\\n### sampled_data Transform Time\\n\\n*  : 0.08958935737609863\\n### kbest Transform Time\\n\\n*  : 0.0010709762573242188\\n### LinearRegression Transform Time\\n\\n*  : 0.0010673999786376953\\n### scaled_target Transform Time\\n\\n*  : 0.0020003318786621094\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_api_pipeline.train(data=train)\n",
    "functional_api_pipeline.test(data=test)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'# Summary: \\n## Summary\\n### RMSE\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### Pipeline Training Time\\n\\n*  : 0.0\\n### CalendarExtraction Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaler_power Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.00264739990234375\\n### LinearRegression Training Time\\n\\n*  : 0.008997678756713867\\n## TransformTime\\n### Pipeline Transform Time\\n\\n*  : 0.025998353958129883\\n### CalendarExtraction Transform Time\\n\\n*  : 0.019034385681152344\\n### imputer_power Transform Time\\n\\n*  : 0.005002260208129883\\n### scaler_power Transform Time\\n\\n*  : 0.0009229183197021484\\n### SampleModule Transform Time\\n\\n*  : 0.011000394821166992\\n### SampleModule Transform Time\\n\\n*  : 0.09299874305725098\\n### kbest Transform Time\\n\\n*  : 0.0009975433349609375\\n### LinearRegression Transform Time\\n\\n*  : 0.000997781753540039\\n### scaler_power Transform Time\\n\\n*  : 0.0020020008087158203\\n'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperative_api_pipeline.train(data=train)\n",
    "imperative_api_pipeline.test(data=test)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What happens under the hood\n",
    "The main method for adding a module to the pipeline via the imperative or the functional API is the `add` method of the pipeline. While the imperative API of pyWATTS uses this method directly, the `__call__` dunder of the functional API uses the mehod by extracting the correct arguments from the provided step information.\n",
    "\n",
    "Internally the `add` method performs three steps:\n",
    "1. The method resets the pipeline to empty the buffer of all pipeline steps in the case the pipeline is executed before. This is necessary to ensure that undesired side effects are minimized.\n",
    "2. It adds the current parameters to a list. This list contains all add statements. We do this to easily rebuild the pipeline if a new step is added.\n",
    "3. We construct the pipeline by calling the `_add` method with the list of add statements. This method iterates through the list and performs mainly the following steps:\n",
    "      1. It looks for a clone of the module/transformer, if already a clone exist it takes the clone if not it creates a new one. We do this to ensure that there are no side effects if a module is changed outside of the pipeline.\n",
    "      2. We search for the steps of the predecessors.\n",
    "      3. We create the module/summary for the current module. Note, one module or summary can lead to the creation of multiple steps. E.g., if EitherOrSteps are used or the predecessors provide multiple outputs.\n",
    "      4. All of these new created step are added to the steps dictionary.\n",
    "\n",
    "  Note the Construction API uses directly the `_add` method\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
