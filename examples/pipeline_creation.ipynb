{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create a Pipeline\n",
    "We provide three ways of creating a pipeline.\n",
    "* Functional API\n",
    "* Imperative API\n",
    "* Constructor API\n",
    "\n",
    "In the following, we briefly describe all three APIs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# From pyWATTS the pipeline is imported\n",
    "from pywatts.callbacks import LinePlotCallback\n",
    "\n",
    "from pywatts_pipeline.core.steps.step import Step\n",
    "from pywatts_pipeline.core.util.computation_mode import ComputationMode\n",
    "from pywatts_pipeline.core.pipeline import Pipeline\n",
    "# All modules required for the pipeline are imported\n",
    "from pywatts.modules import CalendarExtraction, CalendarFeature, ClockShift, LinearInterpolater, SKLearnWrapper, Sampler\n",
    "from pywatts.modules.preprocessing.select import Select\n",
    "from pywatts.summaries import RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functional API\n",
    "\n",
    "The functional API provides an easy way to create pipelines. However, it requires that the call dunder is implemented in the used transformers/modules, which is the case for pyWATTS transformers.\n",
    "The API is inspired by the functional API of Keras. In general the notation is as follows:\n",
    "\n",
    "```Transformer()(x=predeccessor, y=predecessor, ...)```\n",
    "\n",
    "In the following, we show how a simple Pipeline can be created with the Functional API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "functional_api_pipeline = Pipeline(path=\"../results\")\n",
    "\n",
    "# Extract dummy calendar features, using holidays from Germany\n",
    "# NOTE: CalendarExtraction can't return multiple features.\n",
    "\n",
    "functional_preprocessing_pipeline = Pipeline()\n",
    "calendar = CalendarExtraction(continent=\"Europe\",\n",
    "                              country=\"Germany\",name=\"calendar\",\n",
    "                              features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                        CalendarFeature.weekend]\n",
    "                              )(x=functional_preprocessing_pipeline[\"load_power_statistics\"])\n",
    "\n",
    "# Deal with missing values through linear interpolation\n",
    "imputer_power_statistics = LinearInterpolater(method=\"nearest\", dim=\"time\",\n",
    "                                              name=\"imputer_power\"\n",
    "                                              )(x=functional_preprocessing_pipeline[\"load_power_statistics\"])\n",
    "\n",
    "\n",
    "\n",
    "added_prepro_pipe = functional_preprocessing_pipeline(load_power_statistics=functional_api_pipeline[\"load_power_statistics\"])\n",
    "# Create lagged time series to later be used as regressors\n",
    "\n",
    "# Scale the data using a standard SKLearn scaler\n",
    "power_scaler = SKLearnWrapper(module=StandardScaler(), name=\"scaled_input\")\n",
    "scale_power_statistics = power_scaler(x=added_prepro_pipe[\"imputer_power\"])\n",
    "\n",
    "scaler_target = SKLearnWrapper(module=StandardScaler(), name=\"scaled_target\")\n",
    "scaled_target = scaler_target(x=added_prepro_pipe[\"imputer_power\"])\n",
    "\n",
    "\n",
    "\n",
    "lag_features = Select(start=-2, stop=0, step=1)(x=scale_power_statistics)\n",
    "\n",
    "target_multiple_output = Select(start=0, stop=24, step=1, name=\"sampled_data\")(x=scaled_target)\n",
    "\n",
    "# Select features based on F-statistic\n",
    "selected_features = SKLearnWrapper(\n",
    "    module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"\n",
    ")(\n",
    "    lag_features=lag_features,\n",
    "    calendar=added_prepro_pipe[\"calendar\"],\n",
    "    target=scale_power_statistics,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create a linear regression that uses the lagged values to predict the current value\n",
    "# NOTE: SKLearnWrapper has to collect all **kwargs itself and fit it against target.\n",
    "#       It is also possible to implement a join/collect class\n",
    "regressor_power_statistics = SKLearnWrapper(\n",
    "    module=LinearRegression(fit_intercept=True)\n",
    ")(\n",
    "    features=selected_features,\n",
    "    target=target_multiple_output,\n",
    "    callbacks=[LinePlotCallback(\"linear_regression\")],\n",
    ")\n",
    "\n",
    "# Rescale the predictions to be on the original time scale\n",
    "inverse_power_scale = scaler_target(\n",
    "    x=regressor_power_statistics, computation_mode=ComputationMode.Transform,\n",
    "    method=\"inverse_transform\", callbacks=[LinePlotCallback(\"rescale\")]\n",
    ")\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) between the linear regression and the true values\n",
    "# save it as csv file\n",
    "rmse = RMSE()(y_hat=inverse_power_scale, y=target_multiple_output)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<pywatts_pipeline.core.steps.step.Step at 0x1d6da8a9310>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_api_pipeline.steps[\"RMSE_11\"].input_steps[\"y_hat\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': <pywatts_pipeline.core.steps.result_step.ResultStep at 0x1d6dacb7cd0>}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_api_pipeline.steps[\"scaled_target_10\"].input_steps[\"x\"].input_steps[\"features\"].input_steps[\"lag_features\"].input_steps[\"x\"].input_steps\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<pywatts_pipeline.core.steps.pipeline_step.PipelineStep at 0x1d6dacec5b0>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_api_pipeline.steps[\"SampleModule_5\"].input_steps[\"x\"].input_steps[\"x\"].input_steps[\"result\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imperative API\n",
    "\n",
    "The imperative API is an alternative API for pyWATTS Pipelines. It can be used if the transformers do not implement a call dunder.\n",
    "The general notation is as follows\n",
    "\n",
    "```TODO```\n",
    "\n",
    "In the following, we implement the same pipeline as above with a functional API."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<pywatts_pipeline.core.steps.step_information.StepInformation at 0x1d6da8de3d0>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperative_api_pipeline = Pipeline()\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    CalendarExtraction(continent=\"Europe\", country=\"Germany\",\n",
    "                       features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                 CalendarFeature.weekend]),\n",
    "    \"calendar\",\n",
    "    {\"x\": \"load_power_statistics\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    LinearInterpolater(method=\"nearest\", dim=\"time\", name=\"imputer_power\"),\n",
    "    \"imputer\",\n",
    "    {\"x\": \"load_power_statistics\"}\n",
    ")\n",
    "power_scaler = SKLearnWrapper(module=StandardScaler(), name=\"scaler_power\")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    power_scaler,\n",
    "    \"scaler\",\n",
    "    {\"x\": \"imputer\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    Select(start=-2, stop=0, step=1),\n",
    "    \"lag_features\",\n",
    "    {\"x\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    Select(start=0, stop=24, step=1),\n",
    "    \"target\",\n",
    "    {\"x\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    SKLearnWrapper(module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"),\n",
    "    \"selected_features\",\n",
    "    {\"lag_features\": \"lag_features\",\n",
    "     \"calendar\": \"calendar\",\n",
    "     \"target\": \"scaler\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    SKLearnWrapper(module=LinearRegression(fit_intercept=True)),\n",
    "    \"regression\",\n",
    "    {\"selected_features\": \"selected_features\",\n",
    "     \"target\": \"target\"}\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    power_scaler,\n",
    "    \"inverse_scaler\",\n",
    "    {\"x\": \"regression\"},\n",
    "    method=\"inverse_transform\",\n",
    "    callbacks=[LinePlotCallback(\"rescale\")],\n",
    "    computation_mode=ComputationMode.Transform\n",
    ")\n",
    "\n",
    "imperative_api_pipeline.add(\n",
    "    RMSE(),\n",
    "    \"rmse\",\n",
    "    {\"y_hat\": \"inverse_scaler\",\n",
    "     \"y\": \"target\"},\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (CalendarExtraction(continent=\"Europe\", country=\"Germany\",\n",
    "                            features=[CalendarFeature.month, CalendarFeature.weekday,\n",
    "                                      CalendarFeature.weekend]),\n",
    "         \"calendar\",\n",
    "         {\"x\": \"load_power_statistics\"}, {}),\n",
    "        (LinearInterpolater(method=\"nearest\", dim=\"time\", name=\"imputer_power\"),\n",
    "         \"imputer\",\n",
    "         {\"x\": \"load_power_statistics\"}, {}),\n",
    "        (power_scaler,\n",
    "         \"scaler\",\n",
    "         {\"x\": \"imputer\"}, {}),\n",
    "        (Select(start=-2, stop=0, step=1),\n",
    "         \"lag_features\",\n",
    "         {\"x\": \"scaler\"}, {}),\n",
    "        (Select(start=0, stop=24, step=1),\n",
    "         \"target\",\n",
    "         {\"x\": \"scaler\"}, {}),\n",
    "        (SKLearnWrapper(module=SelectKBest(score_func=f_regression, k=2), name=\"kbest\"),\n",
    "         \"selected_features\",\n",
    "         {\"lag_features\": \"lag_features\",\n",
    "          \"calendar\": \"calendar\",\n",
    "          \"target\": \"scaler\"}, {}),\n",
    "        (SKLearnWrapper(module=LinearRegression(fit_intercept=True)),\n",
    "         \"regression\",\n",
    "         {\"selected_features\": \"selected_features\",\n",
    "          \"target\": \"target\"}, {}),\n",
    "        (power_scaler,\n",
    "         \"inverse_scaler\",\n",
    "         {\"x\": \"regression\"},\n",
    "         {\"method\": \"inverse_transform\",\n",
    "          \"callbacks\": [LinePlotCallback(\"rescale\")],\n",
    "          \"computation_mode\": ComputationMode.Transform}),\n",
    "        (RMSE(),\n",
    "         \"rmse\",\n",
    "         {\"y_hat\": \"inverse_scaler\",\n",
    "          \"y\": \"target\"}, {})\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\n",
    "# Now, the pipeline is complete, so we can run it and explore the results\n",
    "# Start the pipeline\n",
    "data = pd.read_csv(\"../data/getting_started_data.csv\",\n",
    "                   index_col=\"time\",\n",
    "                   parse_dates=[\"time\"],\n",
    "                   infer_datetime_format=True,\n",
    "                   sep=\",\")\n",
    "train = data.iloc[:6000, :]\n",
    "test = data.iloc[6000:, :]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'scaler_power': <xarray.DataArray (time: 2758, dim_0: 24)>\n  array([[43784.37968947, 44585.98767846, 46033.62055118, ...,\n          49929.25950573, 48459.51745291, 47531.47191973],\n         [43863.43546587, 45095.85801789, 46830.32152086, ...,\n          48623.11376573, 47609.78597417, 47286.44651005],\n         [44481.44016144, 46053.34130171, 47980.73351623, ...,\n          47835.39356861, 47265.71193995, 47493.23873665],\n         ...,\n         [48946.71547956, 47752.69557672, 47542.44980835, ...,\n          58382.33128245, 55634.01406664, 52644.64087873],\n         [48881.27605756, 48852.27352017, 49434.30822163, ...,\n          54728.87453212, 53172.59737633, 51781.11801085],\n         [49325.56967491, 49982.3026384 , 51001.92720637, ...,\n          52788.26133735, 52006.60213568, 51620.25933718]])\n  Coordinates:\n    * time     (time) datetime64[ns] 2018-09-08T02:00:00 ... 2018-12-31T23:00:00\n    * dim_0    (dim_0) int32 0 1 2 3 4 5 6 7 8 9 ... 14 15 16 17 18 19 20 21 22 23},\n '# Summary: \\n## Summary\\n### RMSE\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### CalendarExtraction Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaler_power Training Time\\n\\n*  : 0.0019910335540771484\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.02920365333557129\\n### LinearRegression Training Time\\n\\n*  : 0.016900300979614258\\n## TransformTime\\n### CalendarExtraction Transform Time\\n\\n*  : 0.02782917022705078\\n### imputer_power Transform Time\\n\\n*  : 0.004024505615234375\\n### scaler_power Transform Time\\n\\n*  : 0.0010030269622802734\\n### SampleModule Transform Time\\n\\n*  : 0.012944936752319336\\n### SampleModule Transform Time\\n\\n*  : 0.1222832202911377\\n### kbest Transform Time\\n\\n*  : 0.0009572505950927734\\n### LinearRegression Transform Time\\n\\n*  : 0.002981901168823242\\n### scaler_power Transform Time\\n\\n*  : 0.0019881725311279297\\n')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train(data=train)\n",
    "pipeline.test(data=test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from pywatts_pipeline.core.transformer.base import BaseEstimator\n",
    "\n",
    "for s in pipeline.steps:\n",
    "    if isinstance(s[0], Step) and isinstance(s[0].module, BaseEstimator):\n",
    "        print(s[0].name, s[0].module.is_fitted, id(s[0].module))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'calendar': <xarray.DataArray (time: 2760, features: 3)>\n  array([[ 8,  5,  1],\n         [ 8,  5,  1],\n         [ 8,  5,  1],\n         ...,\n         [11,  0,  0],\n         [11,  0,  0],\n         [11,  0,  0]], dtype=int64)\n  Coordinates:\n    * time      (time) datetime64[ns] 2018-09-08 ... 2018-12-31T23:00:00\n    * features  (features) int32 2 11 21,\n  'imputer_power': <xarray.DataArray 'load_power_statistics' (time: 2760)>\n  array([45126.3469388, 43935.5408163, 43418.7346939, ..., 49750.2959184,\n         49220.       , 47147.9183673])\n  Coordinates:\n    * time     (time) datetime64[ns] 2018-09-08 ... 2018-12-31T23:00:00,\n  'scaled_target': <xarray.DataArray (time: 2758, dim_0: 24)>\n  array([[43784.37968947, 44585.98767846, 46033.62055118, ...,\n          49929.25950573, 48459.51745291, 47531.47191973],\n         [43863.43546587, 45095.85801789, 46830.32152086, ...,\n          48623.11376573, 47609.78597417, 47286.44651005],\n         [44481.44016144, 46053.34130171, 47980.73351623, ...,\n          47835.39356861, 47265.71193995, 47493.23873665],\n         ...,\n         [48946.71547956, 47752.69557672, 47542.44980835, ...,\n          58382.33128245, 55634.01406664, 52644.64087873],\n         [48881.27605756, 48852.27352017, 49434.30822163, ...,\n          54728.87453212, 53172.59737633, 51781.11801085],\n         [49325.56967491, 49982.3026384 , 51001.92720637, ...,\n          52788.26133735, 52006.60213568, 51620.25933718]])\n  Coordinates:\n    * time     (time) datetime64[ns] 2018-09-08T02:00:00 ... 2018-12-31T23:00:00\n    * dim_0    (dim_0) int32 0 1 2 3 4 5 6 7 8 9 ... 14 15 16 17 18 19 20 21 22 23},\n '# Summary: \\n## Summary\\n### RMSE_11\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### Pipeline Training Time\\n\\n*  : 0.0\\n### calendar Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaled_input Training Time\\n\\n*  : 0.0009949207305908203\\n### scaled_target Training Time\\n\\n*  : 0.0009613037109375\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### sampled_data Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.0028531551361083984\\n### LinearRegression Training Time\\n\\n*  : 0.012919187545776367\\n## TransformTime\\n### Pipeline Transform Time\\n\\n*  : 0.018887758255004883\\n### calendar Transform Time\\n\\n*  : 0.014916419982910156\\n### imputer_power Transform Time\\n\\n*  : 0.0039713382720947266\\n### scaled_input Transform Time\\n\\n*  : 0.0009984970092773438\\n### scaled_target Transform Time\\n\\n*  : 0.0010225772857666016\\n### SampleModule Transform Time\\n\\n*  : 0.008911609649658203\\n### sampled_data Transform Time\\n\\n*  : 0.08157706260681152\\n### kbest Transform Time\\n\\n*  : 0.0009632110595703125\\n### LinearRegression Transform Time\\n\\n*  : 0.0019822120666503906\\n### scaled_target Transform Time\\n\\n*  : 0.000995635986328125\\n')"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_api_pipeline.train(data=train)\n",
    "functional_api_pipeline.test(data=test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pywatts-pipeline\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'scaler_power': <xarray.DataArray (time: 2758, dim_0: 24)>\n  array([[43784.37968947, 44585.98767846, 46033.62055118, ...,\n          49929.25950573, 48459.51745291, 47531.47191973],\n         [43863.43546587, 45095.85801789, 46830.32152086, ...,\n          48623.11376573, 47609.78597417, 47286.44651005],\n         [44481.44016144, 46053.34130171, 47980.73351623, ...,\n          47835.39356861, 47265.71193995, 47493.23873665],\n         ...,\n         [48946.71547956, 47752.69557672, 47542.44980835, ...,\n          58382.33128245, 55634.01406664, 52644.64087873],\n         [48881.27605756, 48852.27352017, 49434.30822163, ...,\n          54728.87453212, 53172.59737633, 51781.11801085],\n         [49325.56967491, 49982.3026384 , 51001.92720637, ...,\n          52788.26133735, 52006.60213568, 51620.25933718]])\n  Coordinates:\n    * time     (time) datetime64[ns] 2018-09-08T02:00:00 ... 2018-12-31T23:00:00\n    * dim_0    (dim_0) int32 0 1 2 3 4 5 6 7 8 9 ... 14 15 16 17 18 19 20 21 22 23},\n '# Summary: \\n## Summary\\n### RMSE\\n\\n* y_hat : 59471.781035211294\\n## FitTime\\n### CalendarExtraction Training Time\\n\\n*  : 0.0\\n### imputer_power Training Time\\n\\n*  : 0.0\\n### scaler_power Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### SampleModule Training Time\\n\\n*  : 0.0\\n### kbest Training Time\\n\\n*  : 0.001992464065551758\\n### LinearRegression Training Time\\n\\n*  : 0.008943319320678711\\n## TransformTime\\n### CalendarExtraction Transform Time\\n\\n*  : 0.013927221298217773\\n### imputer_power Transform Time\\n\\n*  : 0.003939151763916016\\n### scaler_power Transform Time\\n\\n*  : 0.0010020732879638672\\n### SampleModule Transform Time\\n\\n*  : 0.009937524795532227\\n### SampleModule Transform Time\\n\\n*  : 0.09049773216247559\\n### kbest Transform Time\\n\\n*  : 0.0009920597076416016\\n### LinearRegression Transform Time\\n\\n*  : 0.0019948482513427734\\n### scaler_power Transform Time\\n\\n*  : 0.0016319751739501953\\n')"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperative_api_pipeline.train(data=train)\n",
    "imperative_api_pipeline.test(data=test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
